 THUEE-CMCC Dialog System V1.0





KMS Lighthouse Extends Its Knowledge Base Integration to Freshworks Marketplace

Freshworks Inc., the customer engagement software company, and KMS Lighthouse, a cutting-edge knowledge management solutions provider announced an offering to integrate expanded support for existing Freshworks customers. Together, these integrated solutions boost agent response efficiency by providing them access to a powerful, centralized knowledge base that in turn enhances customer satisfaction. 











['Title:Knowledge of Uncertain Worlds: Programming with Logical Constraints'],Artificial Intelligence ,(Submitted on 23 Oct 2019),"Abstract:  Programming with logic for sophisticated applications must deal with recursion and negation, which have created significant challenges in logic,leading to many different, conflicting semantics of rules. This paper describes a unified language, DA logic, for design and analysis logic, based on the unifying founded semantics and constraint semantics, that support the power and ease of programming with different intended semantics. The key idea is to provide meta constraints, support the use of uncertain information in the form of either undefined values or possible combinations of values, and promote the use of knowledge units that can be instantiated by any new predicates,including predicates with additional arguments.",https://arxiv.org/abs/1910.10346





['Title: Faster and Safer Training by Embedding High-Level Knowledge into Deep Reinforcement Learning'],Artificial Intelligence ,(Submitted on 22 Oct 2019),"Abstract:  Deep reinforcement learning has been successfully used in many dynamic decision making domains, especially those with very large state spaces. However, it is also well-known that deep reinforcement learning can be very slow and resource intensive. The resulting system is often brittle and difficult to explain. In this paper, we attempt to address some of these problems by proposing a framework of Rule-interposing Learning (RIL) that embeds high level rules into the deep reinforcement learning. With some good rules, this framework not only can accelerate the learning process, but also keep it away from catastrophic explorations, thus making the system relatively stable even during the very early stage of training. Moreover, given the rules are high level and easy to interpret, they can be easily maintained, updated and shared with other similar tasks.",https://arxiv.org/abs/1910.09986

['Title:Towards More Sample Efficiency in Reinforcement Learning with Data Augmentation'],Artificial Intelligence ,"(Submitted on 19 Oct 2019 (v1), last revised 23 Oct 2019 (this version, v2))","Abstract:  Deep reinforcement learning (DRL) is a promising approach for adaptive robotcontrol, but its current application to robotics is currently hindered by high sample requirements. We propose two novel data augmentation techniques for DRL in order to reuse more efficiently observed data. The first one called Kaleidoscope Experience Replay exploits reflectional symmetries, while the second called Goal-augmented Experience Replay takes advantage of lax goal definitions. Our preliminary experimental results show a large increase in learning speed.",https://arxiv.org/abs/1910.09959









['Title: Phase Transition Behavior of Cardinality and XOR Constraints'],Artificial Intelligence ,(Submitted on 22 Oct 2019),"Abstract:  The runtime performance of modern SAT solvers is deeply connected to the phase transition behaviour of CNF formulas. While CNF solving has witnessed significant runtime improvement over the past two decades, the same does not hold for several other classes such as the conjunction of cardinality and XOR constraints, denoted as CARD-XOR formulas. The problem of determining the satisfiability of CARD-XOR formulas is a fundamental problem with a wide variety of applications ranging from discrete integration in the field of artificial intelligence to maximum likelihood decoding in coding theory. The runtime behavior of random CARD-XOR formulas is unexplored in prior work. In this paper, we present the first rigorous empirical study to characterize the runtime behavior of 1-CARD-XOR formulas. We show empirical evidence of a surprising phase-transition that follows a non-linear trade off between CARD and XOR constraints.",https://arxiv.org/abs/1910.09755



['Title:Intelligence via ultrafilters: structural properties of some intelligence comparators of deterministic Legg-Hutter agents'],Artificial Intelligence ,(Submitted on 22 Oct 2019),"Abstract:  Legg and Hutter, as well as subsequent authors, considered intelligent agents through the lens of interaction with reward-giving environments, attempting to assign numeric intelligence measures to such agents, with the guiding principle that a more intelligent agent should gain higher rewards from environments in some aggregate sense. In this paper, we consider a related question: rather than measure numeric intelligence of one Legg- Hutter agent, how can we compare the relative intelligence of two Legg-Hutter agents? We propose an elegant answer based on the following insight: we can view Legg-Hutter agents as candidates in an election, whose voters are environments, letting each environment vote (via its rewards) which agent (if either) is more intelligent. This leads to an abstract family of comparators simple enough that we can provesome structural theorems about them. It is an open question whether these structural theorems apply to more practical intelligence measures.",https://arxiv.org/abs/1910.09721

['Title:Language-guided Semantic Mapping and Mobile Manipulation in Partially Observable Environments'],Artificial Intelligence ,(Submitted on 22 Oct 2019),"Abstract:  Recent advances in data-driven models for grounded language understandinghave enabled robots to interpret increasingly complex instructions. Twofundamental limitations of these methods are that most require a full model ofthe environment to be known a priori, and they attempt to reason over a worldrepresentation that is flat and unnecessarily detailed, which limitsscalability. Recent semantic mapping methods address partial observability byexploiting language as a sensor to infer a distribution over topological,metric and semantic properties of the environment. However, maintaining adistribution over highly detailed maps that can support grounding of diverseinstructions is computationally expensive and hinders real-time human-robotcollaboration. We propose a novel framework that learns to adapt perceptionaccording to the task in order to maintain compact distributions over semanticmaps. Experiments with a mobile manipulator demonstrate more efficientinstruction following in a priori unknown environments.",https://arxiv.org/abs/1910.10034

['Title:A simple and effective hybrid genetic search for the job sequencing and tool switching problem'],Artificial Intelligence ,(Submitted on 10 Oct 2019),"Abstract:  The job sequencing and tool switching problem (SSP) has been extensivelystudied in the field of operations research, due to its practical relevance andmethodological interest. Given a machine that can load a limited amount oftools simultaneously and a number of jobs that require a subset of theavailable tools, the SSP seeks a job sequence that minimizes the number of toolswitches in the machine. To solve this problem, we propose a simple andefficient hybrid genetic search based on a generic solution representation, atailored decoding operator, efficient local searches and diversity managementtechniques. To guide the search, we introduce a secondary objective designed tobreak ties. These techniques allow to explore structurally different solutionsand escape local optima. As shown in our computational experiments on classicalbenchmark instances, our algorithm significantly outperforms all previousapproaches while remaining simple to apprehend and easy to implement. Wefinally report results on a new set of larger instances to stimulate futureresearch and comparative analyses.",https://arxiv.org/abs/1910.10021

['Title:Learning Resilient Behaviors for Navigation Under Uncertainty Environments'],Artificial Intelligence ,(Submitted on 22 Oct 2019),"Abstract:  Deep reinforcement learning has great potential to acquire complex, adaptivebehaviors for autonomous agents automatically. However, the underlying neuralnetwork polices have not been widely deployed in real-world applications,especially in these safety-critical tasks (e.g., autonomous driving). One ofthe reasons is that the learned policy cannot perform flexible and resilientbehaviors as traditional methods to adapt to diverse environments. In this paper, we consider the problem that a mobile robot learns adaptive and resilient behaviors for navigating in unseen uncertain environments whileavoiding collisions. We present a novel approach for uncertainty-awarenavigation by introducing an uncertainty-aware predictor to model theenvironmental uncertainty, and we propose a novel uncertainty-aware navigationnetwork to learn resilient behaviors in the prior unknown environments. Totrain the proposed uncertainty-aware network more stably and efficiently, wepresent the temperature decay training paradigm, which balances exploration andexploitation during the training process. Our experimental evaluationdemonstrates that our approach can learn resilient behaviors in diverseenvironments and generate adaptive trajectories according to environmentaluncertainties.",https://arxiv.org/abs/1910.09998

['Title:Artificial Intelligence and the Future of Psychiatry: Qualitative Findings from a Global Physician Survey'],Artificial Intelligence ,(Submitted on 22 Oct 2019),"Abstract:  The potential for machine learning to disrupt the medical profession is thesubject of ongoing debate within biomedical informatics. This study aimed toexplore psychiatrists' opinions about the potential impact of innovations inartificial intelligence and machine learning on psychiatric practice. In Spring2019, we conducted a web-based survey of 791 psychiatrists from 22 countriesworldwide. The survey measured opinions about the likelihood future technologywould fully replace physicians in performing ten key psychiatric tasks. Thisstudy involved qualitative descriptive analysis of written response to threeopen-ended questions in the survey. Comments were classified into four majorcategories in relation to the impact of future technology onpatient-psychiatric interactions, the quality of patient medical care, theprofession of psychiatry, and health systems. Overwhelmingly, psychiatristswere skeptical that technology could fully replace human empathy. Manypredicted that 'man and machine' would increasingly collaborate in undertakingclinical decisions, with mixed opinions about the benefits and harms of such anarrangement. Participants were optimistic that technology might improveefficiencies and access to care, and reduce costs. Ethical and regulatoryconsiderations received limited attention. This study presents timelyinformation of psychiatrists' view about the scope of artificial intelligenceand machine learning on psychiatric practice. Psychiatrists expressed divergentviews about the value and impact of future technology with worrying omissionsabout practice guidelines, and ethical and regulatory issues.",https://arxiv.org/abs/1910.09956
['Title:Embedded Bayesian Network Classifiers'],Artificial Intelligence ,(Submitted on 22 Oct 2019),"Abstract:  Low-dimensional probability models for local distribution functions in aBayesian network include decision trees, decision graphs, and causalindependence models. We describe a new probability model for discrete Bayesiannetworks, which we call an embedded Bayesian network classifier or EBNC. Themodel for a node $Y$ given parents $\bf X$ is obtained from a (usuallydifferent) Bayesian network for $Y$ and $\bf X$ in which $\bf X$ need not bethe parents of $Y$. We show that an EBNC is a special case of a softmaxpolynomial regression model. Also, we show how to identify a non-redundant setof parameters for an EBNC, and describe an asymptotic approximation forlearning the structure of Bayesian networks that contain EBNCs. Unlike thedecision tree, decision graph, and causal independence models, we are unawareof a semantic justification for the use of these models. Experiments are neededto determine whether the models presented in this paper are useful in practice.",https://arxiv.org/abs/1910.09715
['Title:ALGAMES: A Fast Solver for Constrained Dynamic Games'],Artificial Intelligence ,(Submitted on 22 Oct 2019),"Abstract:  Dynamic games are an effective paradigm for dealing with the control ofmultiple interacting actors. Current algorithms for solving these problemseither rely on Hamilton-Jacobi-Isaacs (HJI) methods, dynamic programming (DP),differential dynamic programming (DDP), or an iterative best response approach(IBR). The first two approaches have strong theoretical guarantees; howeverthey becomes intractable in high-dimensional real-world applications. The thirdapproach is grounded in the success of iLQR. It is scalable, but it cannothandle constraints. Finally, the iterative best response algorithm is aheuristic approach with unknown convergence properties, and it can suffer fromstability and tractability issues. This paper introduces ALGAMES (AugmentedLagrangian GAME-theoretic Solver), a solver that handles trajectoryoptimization problems with multiple actors and general nonlinear state andinput constraints. We evaluate our solver in the context of autonomous drivingon scenarios involving numerous vehicles such as ramp merging, overtaking, andlane changing. We present simulation and timing results demonstrating the speedand the ability of the solver to produce efficient, safe, and naturalautonomous behaviors.",https://arxiv.org/abs/1910.09713

# 21



['Title:Learning to Map Natural Language Instructions to Physical Quadcopter Control using Simulated Flight'],Artificial Intelligence ,(Submitted on 21 Oct 2019),"Abstract:  We propose a joint simulation and real-world learning framework for mappingnavigation instructions and raw first-person observations to continuouscontrol. Our model estimates the need for environment exploration, predicts thelikelihood of visiting environment positions during execution, and controls theagent to both explore and visit high-likelihood positions. We introduceSupervised Reinforcement Asynchronous Learning (SuReAL). Learning uses bothsimulation and real environments without requiring autonomous flight in thephysical environment during training, and combines supervised learning forpredicting positions to visit and reinforcement learning for continuouscontrol. We evaluate our approach on a natural language instruction-followingtask with a physical quadcopter, and demonstrate effective execution andexploration behavior.",https://arxiv.org/abs/1910.09664
['Title:Relative Net Utility and the Saint Petersburg Paradox'],Artificial Intelligence ,(Submitted on 21 Oct 2019),"Abstract:  The famous St Petersburg Paradox shows that the theory of expected value doesnot capture the real-world economics of decision-making problem. Over theyears, many economic theories were developed to resolve the paradox and explainthe subjective utility of the expected outcomes and risk aversion. In thispaper, we use the concept of the net utility to resolve the St Petersburgparadox. The reason why the principle of absolute instead of net utility doesnot work is because it is a first order approximation of some unknown utilityfunction. Because the net utility concept is able to explain both behavioraleconomics and the St Petersburg paradox it is deemed a universal approach tohandling utility. Finally, this paper explored how artificial intelligent (AI)agent will make choices and observed that if AI agent uses the nominal utilityapproach it will see infinite reward while if it uses the net utility approachit will see the limited reward that human beings see.",https://arxiv.org/abs/1910.09544
['Title:Toward automatic comparison of visualization techniques: Application to graph visualization'],Artificial Intelligence ,(Submitted on 21 Oct 2019),"Abstract:  Many end-user evaluations of data visualization techniques have been runduring the last decades. Their results are cornerstones to build efficientvisualization systems. However, designing an evaluation is always complex andtime-consuming and may end in a lack of statistical evidence. The raising ofmodern efficient computer vision techniques may help visualization researchersto adjust their evaluation hypothesis and thus reduces the risk of failure. Inthis paper, we present a methodology that uses such computer vision techniquesto automatically compare the efficiency of several visualization techniques.The basis of our methodology is to generate a set of images for each comparedvisualization technique from a common dataset and to train machine learningmodels (one for each set and visualization technique) to solve a given task.Our assumption is that the performance of each model allows to compare theefficiencies of the corresponding visualization techniques; as current machinelearning models are not capable enough to reflect human capabilities, includingtheir imperfections, such results should be interpreted with caution. However,we argue that using machine learning-based evaluation as a pre-process ofstandard user evaluations should help researchers to perform a more exhaustivestudy of the design space and thus should improve the final user evaluation byproviding better test cases. To show that our methodology can reproduce, up toa certain level, results of user evaluations, we applied it to compare twomainstream graph visualization techniques: node-link (NL) and adjacency-matrix(MD) diagrams. We partially reproduced a user evaluation from Ghoniem et al.using two well-known deep convolutional neural networks as machinelearning-based systems. Our results show up that Ghoniem et al. results can bereproduced automatically at a larger scale with our system.",https://arxiv.org/abs/1910.09477
['Title:A Logic-Based Framework Leveraging Neural Networks for Studying the Evolution of Neurological Disorders'],Artificial Intelligence ,(Submitted on 21 Oct 2019),"Abstract:  Deductive formalisms have been strongly developed in recent years; amongthem, Answer Set Programming (ASP) gained some momentum, and has been latelyfruitfully employed in many real-world scenarios. Nonetheless, in spite of alarge number of success stories in relevant application areas, and even inindustrial contexts, deductive reasoning cannot be considered the ultimate,comprehensive solution to AI; indeed, in several contexts, other approachesresult to be more useful. Typical Bioinformatics tasks, for instanceclassification, are currently carried out mostly by Machine Learning (ML) basedsolutions. In this paper, we focus on the relatively new problem of analyzingthe evolution of neurological disorders. In this context, ML approaches alreadydemonstrated to be a viable solution for classification tasks; here, we showhow ASP can play a relevant role in the brain evolution simulation task. Inparticular, we propose a general and extensible framework to support physiciansand researchers at understanding the complex mechanisms underlying neurologicaldisorders. The framework relies on a combined use of ML and ASP, and is generalenough to be applied in several other application scenarios, which are outlinedin the paper.",https://arxiv.org/abs/1910.09472
['Title:Recurrent neural network approach for cyclic job shop scheduling problem'],Artificial Intelligence ,(Submitted on 21 Oct 2019),"Abstract:  While cyclic scheduling is involved in numerous real-world applications,solving the derived problem is still of exponential complexity. This paperfocuses specifically on modelling the manufacturing application as a cyclic jobshop problem and we have developed an efficient neural network approach tominimise the cycle time of a schedule. Our approach introduces an interestingmodel for a manufacturing production, and it is also very efficient, adaptiveand flexible enough to work with other techniques. Experimental resultsvalidated the approach and confirmed our hypotheses about the system model andthe efficiency of neural networks for such a class of problems.",https://arxiv.org/abs/1910.09437
['Title:Redistribution Mechanism Design on Networks'],Artificial Intelligence ,(Submitted on 21 Oct 2019),"Abstract:  Redistribution mechanisms have been proposed for more efficient resourceallocation but not for profit. We consider redistribution mechanism design forthe first time in a setting where participants are connected and the resourceowner is only aware of her neighbours. In this setting, to make the resourceallocation more efficient, the resource owner has to inform the others who arenot her neighbours, but her neighbours do not want more participants to competewith them. Hence, the goal is to design a redistribution mechanism such thatparticipants are incentivized to invite more participants and the resourceowner does not earn or lose much money from the allocation. We first show thatexisting redistribution mechanisms cannot be directly applied in the networksetting to achieve the goal. Then we propose a novel network-basedredistribution mechanism such that all participants in the network are invited,the allocation is more efficient and the resource owner has no deficit.",https://arxiv.org/abs/1910.09335
"[""Title:Studying Topology of Time Lines Graph leads to an alternative approach to the Newcomb's Paradox""]",Artificial Intelligence ,(Submitted on 15 Oct 2019),Abstract:  The Newcomb's paradox is one of the most known paradox in Game Theory aboutthe Oracles. We will define the graph associated to the time lines of the Game.After this Studying its topology and using only the Expected Utility Principlewe will formulate a solution of the paradox able to explain all the classicalcases.,https://arxiv.org/abs/1910.09311
['Title:All-Action Policy Gradient Methods: A Numerical Integration Approach'],Artificial Intelligence ,(Submitted on 21 Oct 2019),"Abstract:  While often stated as an instance of the likelihood ratio trick [Rubinstein,1989], the original policy gradient theorem [Sutton, 1999] involves an integralover the action space. When this integral can be computed, the resulting""all-action"" estimator [Sutton, 2001] provides a conditioning effect [Bratley,1987] reducing the variance significantly compared to the REINFORCE estimator[Williams, 1992]. In this paper, we adopt a numerical integration perspectiveto broaden the applicability of the all-action estimator to general spaces andto any function class for the policy or critic components, beyond the Gaussiancase considered by [Ciosek, 2018]. In addition, we provide a new theoreticalresult on the effect of using a biased critic which offers more guidance thanthe previous ""compatible features"" condition of [Sutton, 1999]. We demonstratethe benefit of our approach in continuous control tasks with nonlinear functionapproximation. Our results show improved performance and sample efficiency.",https://arxiv.org/abs/1910.09093
['Title:Neuro-SERKET: Development of Integrative Cognitive System through the Composition of Deep Probabilistic Generative Models'],Artificial Intelligence ,(Submitted on 20 Oct 2019),"Abstract:  This paper describes a framework for the development of an integrativecognitive system based on probabilistic generative models (PGMs) calledNeuro-SERKET. Neuro-SERKET is an extension of SERKET, which can composeelemental PGMs developed in a distributed manner and provide a scheme thatallows the composed PGMs to learn throughout the system in an unsupervised way.In addition to the head-to-tail connection supported by SERKET, Neuro-SERKETsupports tail-to-tail and head-to-head connections, as well as neuralnetwork-based modules, i.e., deep generative models. As an example of aNeuro-SERKET application, an integrative model was developed by composing avariational autoencoder (VAE), a Gaussian mixture model (GMM), latent Dirichletallocation (LDA), and automatic speech recognition (ASR). The model is calledVAE+GMM+LDA+ASR. The performance of VAE+GMM+LDA+ASR and the validity ofNeuro-SERKET were demonstrated through a multimodal categorization task usingimage data and a speech signal of numerical digits.",https://arxiv.org/abs/1910.08918
['Title:Solving dynamic multi-objective optimization problems via support vector machine'],Artificial Intelligence ,(Submitted on 19 Oct 2019),"Abstract:  Dynamic Multi-objective Optimization Problems (DMOPs) refer to optimizationproblems that objective functions will change with time. Solving DMOPs impliesthat the Pareto Optimal Set (POS) at different moments can be accurately found,and this is a very difficult job due to the dynamics of the optimizationproblems. The POS that have been obtained in the past can help us to find thePOS of the next time more quickly and accurately. Therefore, in this paper wepresent a Support Vector Machine (SVM) based Dynamic Multi-ObjectiveEvolutionary optimization Algorithm, called SVM-DMOEA. The algorithm uses thePOS that has been obtained to train a SVM and then take the trained SVM toclassify the solutions of the dynamic optimization problem at the next moment,and thus it is able to generate an initial population which consists ofdifferent individuals recognized by the trained SVM. The initial populuationcan be fed into any population based optimization algorithm, e.g., theNondominated Sorting Genetic Algorithm II (NSGA-II), to get the POS at thatmoment. The experimental results show the validity of our proposed approach.",https://arxiv.org/abs/1910.08747
['Title:CreditPrint: Credit Investigation via Geographic Footprints by Deep Learning'],Artificial Intelligence ,(Submitted on 19 Oct 2019),"Abstract:  Credit investigation is critical for financial services. Whereas, traditionalmethods are often restricted as the employed data hardly provide sufficient,timely and reliable information. With the prevalence of smart mobile devices,peoples' geographic footprints can be automatically and constantly collectednowadays, which provides an unprecedented opportunity for creditinvestigations. Inspired by the observation that locations are somehow relatedto peoples' credit level, this research aims to enhance credit investigationwith users' geographic footprints. To this end, a two-stage creditinvestigation framework is designed, namely CreditPrint. In the first stage,CreditPrint explores regions' credit characteristics and learns a credit-awareembedding for each region by considering both each region's individualcharacteristics and cross-region relationships with graph convolutionalnetworks. In the second stage, a hierarchical attention-based credit assessmentnetwork is proposed to aggregate the credit indications from a user's multipletrajectories covering diverse regions. The results on real-life user mobilitydatasets show that CreditPrint can increase the credit investigation accuracyby up to 10% compared to baseline methods.",https://arxiv.org/abs/1910.08734
['Title:Optimal Immunization Policy Using Dynamic Programming'],Artificial Intelligence ,(Submitted on 19 Oct 2019),"Abstract:  Decisions in public health are almost always made in the context ofuncertainty. Policy makers responsible for making important decisions are facedwith the daunting task of choosing from many possible options. This task iscalled planning under uncertainty, and is particularly acute when addressingcomplex systems, such as issues of global health and development. Decisionmaking under uncertainty is a challenging task, and all too often thisuncertainty is averaged away to simplify results for policy makers. A popularway to approach this task is to formulate the problem at hand as a (partiallyobservable) Markov decision process, (PO)MDP. This work aims to apply these AIefforts to challenging problems in health and development. In this paper, wedeveloped a framework for optimal health policy design in a dynamic setting. Weapply a stochastic dynamic programing approach to identify both the optimaltime to change the health intervention policy and the optimal time to collectdecision relevant information.",https://arxiv.org/abs/1910.08677
['Title:Blameworthiness in Security Games'],Artificial Intelligence ,(Submitted on 18 Oct 2019),Abstract:  Security games are an example of a successful real-world application of gametheory. The paper defines blameworthiness of the defender and the attacker insecurity games using the principle of alternative possibilities and provides asound and complete logical system for reasoning about blameworthiness in suchgames. Two of the axioms of this system capture the asymmetry of information insecurity games.,https://arxiv.org/abs/1910.08647
['Title:Neural Logic Networks'],Artificial Intelligence ,(Submitted on 17 Oct 2019),"Abstract:  Recent years have witnessed the great success of deep neural networks in manyresearch areas. The fundamental idea behind the design of most neural networksis to learn similarity patterns from data for prediction and inference, whichlacks the ability of logical reasoning. However, the concrete ability oflogical reasoning is critical to many theoretical and practical problems. Inthis paper, we propose Neural Logic Network (NLN), which is a dynamic neuralarchitecture that builds the computational graph according to input logicalexpressions. It learns basic logical operations as neural modules, and conductspropositional logical reasoning through the network for inference. Experimentson simulated data show that NLN achieves significant performance on solvinglogical equations. Further experiments on real-world data show that NLNsignificantly outperforms state-of-the-art models on collaborative filteringand personalized recommendation tasks.",https://arxiv.org/abs/1910.08629
['Title:Comparing Greedy Constructive Heuristic Subtour Elimination Methods for the Traveling Salesman Problem'],Artificial Intelligence ,(Submitted on 15 Oct 2019),"Abstract:  This paper further defines the class of fragment constructive heuristics usedto compute feasible solutions for the Traveling Salesman Problem intoarc-greedy and node-greedy subclasses. Since these subclasses of heuristics cancreate subtours, two known methodologies for subtour elimination on symmetricinstances are reviewed and are expanded to cover asymmetric problem instances.This paper introduces a third novel methodology, the Greedy Tracker, andcompares it to both known methodologies. Computational results are generatedacross multiple symmetric and asymmetric instances. The results demonstrate theGreedy Tracker is the fastest method for preventing subtours for instancesbelow 400 nodes. A distinction between fragment constructive heuristics and thesubtour elimination methodology used to ensure the feasibility of resultingsolutions enables the introduction of a new node-greedy fragment heuristiccalled Ordered Greedy.",https://arxiv.org/abs/1910.08625
['Title:Multi-agent Hierarchical Reinforcement Learning with Dynamic Termination'],Artificial Intelligence ,(Submitted on 21 Oct 2019),"Abstract:  In a multi-agent system, an agent's optimal policy will typically depend onthe policies chosen by others. Therefore, a key issue in multi-agent systemsresearch is that of predicting the behaviours of others, and respondingpromptly to changes in such behaviours. One obvious possibility is for eachagent to broadcast their current intention, for example, the currently executedoption in a hierarchical reinforcement learning framework. However, thisapproach results in inflexibility of agents if options have an extendedduration and are dynamic. While adjusting the executed option at each stepimproves flexibility from a single-agent perspective, frequent changes inoptions can induce inconsistency between an agent's actual behaviour and itsbroadcast intention. In order to balance flexibility and predictability, wepropose a dynamic termination Bellman equation that allows the agents toflexibly terminate their options. We evaluate our model empirically on a set ofmulti-agent pursuit and taxi tasks, and show that our agents learn to adaptflexibly across scenarios that require different termination behaviours.",https://arxiv.org/abs/1910.09508
['Title:Policy Optimization for $\\mathcal{H}_2$ Linear Control with $\\mathcal{H}_\\infty$ Robustness Guarantee: Implicit Regularization and Global Convergence'],Artificial Intelligence ,(Submitted on 21 Oct 2019),"Abstract:  Policy optimization (PO) is a key ingredient for reinforcement learning (RL).For control design, certain constraints are usually enforced on the policies tooptimize, accounting for either the stability, robustness, or safety concernson the system. Hence, PO is by nature a constrained (nonconvex) optimization inmost cases, whose global convergence is challenging to analyze in general. Moreimportantly, some constraints that are safety-critical, e.g., the$\mathcal{H}_\infty$-norm constraint that guarantees the system robustness, aredifficult to enforce as the PO methods proceed. Recently, policy gradientmethods have been shown to converge to the global optimum of linear quadraticregulator (LQR), a classical optimal control problem, withoutregularizing/projecting the control iterates onto the stabilizing set (Fazel etal., 2018), its (implicit) feasible set. This striking result is built upon thecoercive property of the cost, ensuring that the iterates remain feasible asthe cost decreases. In this paper, we study the convergence theory of PO for$\mathcal{H}_2$ linear control with $\mathcal{H}_\infty$-norm robustnessguarantee. One significant new feature of this problem is the lack ofcoercivity, i.e., the cost may have finite value around the feasible setboundary, breaking the existing analyses for LQR. Interestingly, we show thattwo PO methods enjoy the implicit regularization property, i.e., the iteratespreserve the $\mathcal{H}_\infty$ robustness constraint as if they areregularized by the algorithms. Furthermore, convergence to the globally optimalpolicies with globally sublinear and locally (super-)linear rates are providedunder certain conditions, despite the nonconvexity of the problem. To the bestof our knowledge, our work offers the first results on the implicitregularization property and global convergence of PO methods forrobust/risk-sensitive control.",https://arxiv.org/abs/1910.09496
['Title:S4NN: temporal backpropagation for spiking neural networks with one spike per neuron'],Artificial Intelligence ,(Submitted on 21 Oct 2019),"Abstract:  We propose a new supervised learning rule for multilayer spiking neuralnetworks (SNN) that use a form of temporal coding known as rank-order-coding.With this coding scheme, all neurons fire exactly one spike per stimulus, butthe firing order carries information. In particular, in the readout layer, thefirst neuron to fire determines the class of the stimulus. We derive a newlearning rule for this sort of network, termed S4NN, akin to traditional errorbackpropagation, yet based on latencies. We show how approximate errorgradients can be computed backward in a feedforward network with an arbitrarynumber of layers. This approach reaches state-of-the-art performance with SNNs:test accuracy of 97.4% for the MNIST dataset, and of 99.2% for the CaltechFace/Motorbike dataset. Yet the neuron model we use, non-leakyintegrate-and-fire, are simpler and more hardware friendly than the one used inall previous similar proposals.",https://arxiv.org/abs/1910.09495
['Title:DeepMNavigate: Deep Reinforced Multi-Robot Navigation Unifying Local & Global Collision Avoidance'],Artificial Intelligence ,"(Submitted on 4 Oct 2019 (v1), last revised 22 Oct 2019 (this version, v2))","Abstract:  We present a novel algorithm (DeepMNavigate) for global multi-agentnavigation in dense scenarios using deep reinforcement learning. Our approachuses local and global information for each robot based on motion informationmaps. We use a three-layer CNN that uses these maps as input and generate asuitable action to drive each robot to its goal position. Our approach isgeneral, learns an optimal policy using a multi-scenario, multi-state trainingalgorithm, and can directly handle raw sensor measurements for localobservations. We demonstrate the performance on complex, dense benchmarks withnarrow passages on environments with tens of agents. We highlight thealgorithm's benefits over prior learning methods and geometric decentralizedalgorithms in complex scenarios.",https://arxiv.org/abs/1910.09441
['Title:Maximum Probability Principle and Black-Box Priors'],Artificial Intelligence ,(Submitted on 21 Oct 2019),"Abstract:  We present an axiomatic way of assigning probabilities to black box models.In particular, we quantify an upper bound for probability of a model or interms of information theory, a lower bound for amount of information that isstored in a model. In our setup, maximizing probabilities of models isequivalent to removing assumptions or information stored in the model.Furthermore, we represent the problem of learning from an alternative viewwhere the underlying probability space is considered directly. In thisperspective both the true underlying model and the model at hand are events.Consequently, the problem of learning is represented as minimizing theprobability of the symmetric difference of the model and the true underlyingmodel.",https://arxiv.org/abs/1910.09417
['Title:Making Bayesian Predictive Models Interpretable: A Decision Theoretic Approach'],Artificial Intelligence ,(Submitted on 21 Oct 2019),"Abstract:  A salient approach to interpretable machine learning is to restrict modelingto simple and hence understandable models. In the Bayesian framework, this canbe pursued by restricting the model structure and prior to favor interpretablemodels. Fundamentally, however, interpretability is about users' preferences,not the data generation mechanism: it is more natural to formulateinterpretability as a utility function. In this work, we propose aninterpretability utility, which explicates the trade-off between explanationfidelity and interpretability in the Bayesian framework. The method consists oftwo steps. First, a reference model, possibly a black-box Bayesian predictivemodel compromising no accuracy, is constructed and fitted to the training data.Second, a proxy model from an interpretable model family that best mimics thepredictive behaviour of the reference model is found by optimizing theinterpretability utility function. The approach is model agnostic - neither theinterpretable model nor the reference model are restricted to be from a certainclass of models - and the optimization problem can be solved using standardtools in the chosen model family. Through experiments on real-word data setsusing decision trees as interpretable models and Bayesian additive regressionmodels as reference models, we show that for the same level ofinterpretability, our approach generates more accurate models than the earlieralternative of restricting the prior. We also propose a systematic way tomeasure stabilities of interpretabile models constructed by differentinterpretability approaches and show that our proposed approach generates morestable models.",https://arxiv.org/abs/1910.09358
['Title:Gradient Boosted Decision Tree Neural Network'],Artificial Intelligence ,(Submitted on 17 Oct 2019),"Abstract:  In this paper we propose a method to build a neural network that is similarto an ensemble of decision trees. We first illustrate how to convert a learnedensemble of decision trees to a single neural network with one hidden layer andan input transformation. We then relax some properties of this network such asthresholds and activation functions to train an approximately equivalentdecision tree ensemble. The final model, Hammock, is surprisingly simple: afully connected two layers neural network where the input is quantized andone-hot encoded. Experiments on large and small datasets show this simplemethod can achieve performance similar to that of Gradient Boosted DecisionTrees.",https://arxiv.org/abs/1910.09340
['Title:A Neural Entity Coreference Resolution Review'],Artificial Intelligence ,(Submitted on 21 Oct 2019),"Abstract:  Entity Coreference Resolution is the task of resolving all the mentions in adocument that refer to the same real world entity and is considered as one ofthe most difficult tasks in natural language understanding. While in it is notan end task, it has been proved to improve downstream natural languageprocessing tasks such as entity linking, machine translation, summarization andchatbots. We conducted a systematic a review of neural-based approached andprovide a detailed appraisal of the datasets and evaluation metrics in thefield. Emphasis is given on Pronoun Resolution, a subtask of CoreferenceResolution, which has seen various improvements in the recent years. Weconclude the study by highlight the lack of agreed upon standards and propose away to expand the task even further.",https://arxiv.org/abs/1910.09329
['Title:Trends in the optimal location and sizing of electrical units in smart grids using meta-heuristic algorithms'],Artificial Intelligence ,(Submitted on 16 Oct 2019),"Abstract:  The development of smart grids has effectively transformed the traditionalgrid system. This promises numerous advantages for economic values andautonomous control of energy sources. In smart grids development, there arevarious objectives such as voltage stability, minimized power loss, minimizedeconomic cost and voltage profile improvement. Thus, researchers haveinvestigated several approaches based on meta-heuristic optimization algorithmsfor the optimal location and sizing of electrical units in a distributionsystem. Meta-heuristic algorithms have been applied to solve different problemsin power systems and they have been successfully used in distribution systems.This paper presents a comprehensive review on existing methods for the optimallocation and sizing of electrical units in distribution networks whileconsidering the improvement of major objective functions. Techniques such asvoltage stability index, power loss index, and loss sensitivity factors havebeen implemented alongside the meta-heuristic optimization algorithms to reducethe search space of solutions for objective functions. However, thesetechniques can cause a loss of optimality. Another perceived problem is theinappropriate handling of multiple objectives, which can also affect theoptimality of results. Hence, a recent method such as Pareto fronts generationhas been developed to produce non-dominating solutions. This review shows aneed for more research on (i) the effective handling of multiple objectivefunctions, (ii) more efficient meta-heuristic optimization algorithms and/or(iii) better supporting techniques.",https://arxiv.org/abs/1910.09312
['Title:On Semi-Supervised Multiple Representation Behavior Learning'],Artificial Intelligence ,(Submitted on 21 Oct 2019),"Abstract:  We propose a novel paradigm of semi-supervised learning (SSL)--thesemi-supervised multiple representation behavior learning (SSMRBL). SSMRBL aimsto tackle the difficulty of learning a grammar for natural language parsingwhere the data are natural language texts and the 'labels' for marking data areparsing trees and/or grammar rule pieces. We call such 'labels' as compoundstructured labels which require a hard work for training. SSMRBL is anincremental learning process that can learn more than one representation, whichis an appropriate solution for dealing with the scarce of labeled training datain the age of big data and with the heavy workload of learning compoundstructured labels. We also present a typical example of SSMRBL, regardingbehavior learning in form of a grammatical approach towards domain-basedmultiple text summarization (DBMTS). DBMTS works under the framework ofrhetorical structure theory (RST). SSMRBL includes two representations: textembedding (for representing information contained in the texts) and grammarmodel (for representing parsing as a behavior). The first representation waslearned as embedded digital vectors called impacts in a low dimensional space.The grammar model was learned in an iterative way. Then an automaticdomain-oriented multi-text summarization approach was proposed based on the tworepresentations discussed above. Experimental results on large-scale Chinesedataset SogouCA indicate that the proposed method brings a good performanceeven if only few labeled texts are used for training with respect to ourdefined automated metrics.",https://arxiv.org/abs/1910.09292
['Title:Dealing with Sparse Rewards in Reinforcement Learning'],Artificial Intelligence ,(Submitted on 21 Oct 2019),"Abstract:  Successfully navigating a complex environment to obtain a desired outcome isa difficult task, that up to recently was believed to be capable only byhumans. This perception has been broken down over time, especially with theintroduction of deep reinforcement learning, which has greatly increased thedifficulty of tasks that can be automated. However, for traditionalreinforcement learning agents this requires an environment to be able toprovide frequent extrinsic rewards, which are not known or accessible for manyreal-world environments. This project aims to explore and contrast existingreinforcement learning solutions that circumnavigate the difficulties of anenvironment that provide sparse rewards. Different reinforcement solutions willbe implemented over a several video game environments with varying difficultyand varying frequency of rewards, as to properly investigate the applicabilityof these solutions. This project introduces a novel reinforcement learningsolution, by combining aspects of two existing state of the art sparse rewardsolutions.",https://arxiv.org/abs/1910.09281
['Title:Semi-Decentralized Coordinated Online Learning for Continuous Games with Coupled Constraints via Augmented Lagrangian'],Artificial Intelligence ,(Submitted on 21 Oct 2019),"Abstract:  We consider a class of concave continuous games in which the correspondingadmissible strategy profile of each player underlies affine couplingconstraints. We propose a novel algorithm that leads the relevant populationdynamic toward Nash equilibrium. This algorithm is based on a mirror ascentalgorithm, which suits with the framework of no-regret online learning, and onthe augmented Lagrangian method. The decentralization aspect of the algorithmcorresponds to the aspects that the iterate of each player requires the localinformation about how she contributes to the coupling constraints and the pricevector broadcasted by a central coordinator. So each player needs not knowabout the population action. Moreover, no specific control by the centralprimary coordinator is required. We give a condition on the step sizes and thedegree of the augmentation of the Lagrangian, such that the proposed algorithmconverges to a generalized Nash equilibrium.",https://arxiv.org/abs/1910.09276
['Title:Crypto Mining Makes Noise'],Artificial Intelligence ,(Submitted on 21 Oct 2019),"Abstract:  A new cybersecurity attack (cryptojacking) is emerging, in both theliterature and in the wild, where an adversary illicitly runs Crypto-clientssoftware over the devices of unaware users. This attack has been proved to bevery effective given the simplicity of running a Crypto-client into a targetdevice, e.g., by means of web-based Java scripting. In this scenario, wepropose Crypto-Aegis, a solution to detect and identify Crypto-clients networktraffic--even when it is VPN-ed. In detail, our contributions are thefollowing: (i) We identify and model a new type of attack, i.e., thesponge-attack, being a generalization of cryptojacking; (ii) We provide adetailed analysis of real network traffic generated by 3 majorcryptocurrencies; (iii) We investigate how VPN tunneling shapes the networktraffic generated by Crypto-clients by considering two major VPNbrands; (iv) Wepropose Crypto-Aegis, a Machine Learning (ML) based framework that builds overthe previous steps to detect crypto-mining activities; and, finally, (v) Wecompare our results against competing solutions in the literature. Evidencefrom of our experimental campaign show the exceptional quality and viability ofour solution--Crypto-Aegis achieves an F1-score of 0.96 and an AUC of 0.99.Given the extent and novelty of the addressed threat we believe that ourapproach and our results, other than being interesting on their own, also pavethe way for further research in this area.",https://arxiv.org/abs/1910.09272
['Title:Multi-Band Multi-Resolution Fully Convolutional Neural Networks for Singing Voice Separation'],Artificial Intelligence ,(Submitted on 21 Oct 2019),"Abstract:  Deep neural networks with convolutional layers usually process the entirespectrogram of an audio signal with the same time-frequency resolutions, numberof filters, and dimensionality reduction scale. According to the constant-Qtransform, good features can be extracted from audio signals if the lowfrequency bands are processed with high frequency resolution filters and thehigh frequency bands with high time resolution filters. In the spectrogram of amixture of singing voices and music signals, there is usually more informationabout the voice in the low frequency bands than the high frequency bands. Theseraise the need for processing each part of the spectrogram differently. In thispaper, we propose a multi-band multi-resolution fully convolutional neuralnetwork (MBR-FCN) for singing voice separation. The MBR-FCN processes thefrequency bands that have more information about the target signals with morefilters and smaller dimentionality reduction scale than the bands with lessinformation. Furthermore, the MBR-FCN processes the low frequency bands withhigh frequency resolution filters and the high frequency bands with high timeresolution filters. Our experimental results show that the proposed MBR-FCNwith very few parameters achieves better singing voice separation performancethan other deep neural networks.",https://arxiv.org/abs/1910.09266
['Title:Human-Like Decision Making: Document-level Aspect Sentiment Classification via Hierarchical Reinforcement Learning'],Artificial Intelligence ,(Submitted on 21 Oct 2019),"Abstract:  Recently, neural networks have shown promising results on Document-levelAspect Sentiment Classification (DASC). However, these approaches often offerlittle transparency w.r.t. their inner working mechanisms and lackinterpretability. In this paper, to simulating the steps of analyzing aspectsentiment in a document by human beings, we propose a new HierarchicalReinforcement Learning (HRL) approach to DASC. This approach incorporatesclause selection and word selection strategies to tackle the data noise problemin the task of DASC. First, a high-level policy is proposed to selectaspect-relevant clauses and discard noisy clauses. Then, a low-level policy isproposed to select sentiment-relevant words and discard noisy words inside theselected clauses. Finally, a sentiment rating predictor is designed to providereward signals to guide both clause and word selection. Experimental resultsdemonstrate the impressive effectiveness of the proposed approach to DASC overthe state-of-the-art baselines.",https://arxiv.org/abs/1910.09260
['Title:Constructing Artificial Data for Fine-tuning for Low-Resource Biomedical Text Tagging with Applications in PICO Annotation'],Artificial Intelligence ,(Submitted on 21 Oct 2019),"Abstract:  Biomedical text tagging systems are plagued by the dearth of labeled trainingdata. There have been recent attempts at using pre-trained encoders to dealwith this issue. Pre-trained encoder provides representation of the input textwhich is then fed to task-specific layers for classification. The entirenetwork is fine-tuned on the labeled data from the target task. Unfortunately,a low-resource biomedical task often has too few labeled instances forsatisfactory fine-tuning. Also, if the label space is large, it contains few orno labeled instances for majority of the labels. Most biomedical taggingsystems treat labels as indexes, ignoring the fact that these labels are oftenconcepts expressed in natural language e.g. `Appearance of lesion on brainimaging'. To address these issues, we propose constructing extra labeledinstances using label-text (i.e. label's name) as input for the correspondinglabel-index (i.e. label's index). In fact, we propose a number of strategiesfor manufacturing multiple artificial labeled instances from a single label.The network is then fine-tuned on a combination of real and these newlyconstructed artificial labeled instances. We evaluate the proposed approach onan important low-resource biomedical task called \textit{PICO annotation},which requires tagging raw text describing clinical trials with labelscorresponding to different aspects of the trial i.e. PICO (Population,Intervention/Control, Outcome) characteristics of the trial. Our empiricalresults show that the proposed method achieves a new state-of-the-artperformance for PICO annotation with very significant improvements overcompetitive baselines.",https://arxiv.org/abs/1910.09255
['Title:Regularization Matters in Policy Optimization'],Artificial Intelligence ,(Submitted on 21 Oct 2019),"Abstract:  Deep Reinforcement Learning (Deep RL) has been receiving increasingly moreattention thanks to its encouraging performance on a variety of control tasks.Yet, conventional regularization techniques in training neural networks (e.g.,$L_2$ regularization, dropout) have been largely ignored in RL methods,possibly because agents are typically trained and evaluated in the sameenvironment. In this work, we present the first comprehensive study ofregularization techniques with multiple policy optimization algorithms oncontinuous control tasks. Interestingly, we find conventional regularizationtechniques on the policy networks can often bring large improvement on the taskperformance, and the improvement is typically more significant when the task ismore difficult. We also compare with the widely used entropy regularization andfind $L_2$ regularization is generally better. Our findings are furtherconfirmed to be robust against the choice of training hyperparameters. We alsostudy the effects of regularizing different components and find that onlyregularizing the policy network is typically enough. We hope our study providesguidance for future practices in regularizing policy optimization algorithms.",https://arxiv.org/abs/1910.09191
['Title:Two Case Studies of Experience Prototyping Machine Learning Systems in the Wild'],Artificial Intelligence ,(Submitted on 21 Oct 2019),"Abstract:  Throughout the course of my Ph.D., I have been designing the user experience(UX) of various machine learning (ML) systems. In this workshop, I share twoprojects as case studies in which people engage with ML in much morecomplicated and nuanced ways than the technical HCML work might assume. Thefirst case study describes how cardiology teams in three hospitals used aclinical decision-support system that helps them decide whether and when toimplant an artificial heart to a heart failure patient. I demonstrate thatphysicians cannot draw on their decision-making experience by seeing onlypatient data on paper. They are also confused by some fundamental premises uponwhich ML operates. For example, physicians asked: Are ML predictions made basedon clinicians' best efforts? Is it ethical to make decisions based on previouspatients' collective outcomes? In the second case study, my collaborators and Idesigned an intelligent text editor, with the goal of improving authors'writing experience with NLP (Natural Language Processing) technologies. Weprototyped a number of generative functionalities where the system providesphrase-or-sentence-level writing suggestions upon user request. When writingwith the prototype, however, authors shared that they need to ""see where thesentence is going two paragraphs later"" in order to decide whether thesuggestion aligns with their writing; Some even considered adopting machinesuggestions as plagiarism, therefore ""is simply wrong"".By sharing these unexpected and intriguing responses from these real-world MLusers, I hope to start a discussion about such previously-unknown complexitiesand nuances of -- as the workshop proposal states -- ""putting ML at the serviceof people in a way that is accessible, useful, and trustworthy to all"".",https://arxiv.org/abs/1910.09137
['Title:Unsupervised Out-of-Distribution Detection with Batch Normalization'],Artificial Intelligence ,(Submitted on 21 Oct 2019),"Abstract:  Likelihood from a generative model is a natural statistic for detectingout-of-distribution (OoD) samples. However, generative models have been shownto assign higher likelihood to OoD samples compared to ones from the trainingdistribution, preventing simple threshold-based detection rules. We demonstratethat OoD detection fails even when using more sophisticated statistics based onthe likelihoods of individual samples. To address these issues, we propose anew method that leverages batch normalization. We argue that batchnormalization for generative models challenges the traditional i.i.d. dataassumption and changes the corresponding maximum likelihood objective. Based onthis insight, we propose to exploit in-batch dependencies for OoD detection.Empirical results suggest that this leads to more robust detection forhigh-dimensional images.",https://arxiv.org/abs/1910.09115
['Title:Boosting Mapping Functionality of Neural Networks via Latent Feature Generation based on Reversible Learning'],Artificial Intelligence ,(Submitted on 21 Oct 2019),"Abstract:  This paper addresses a boosting method for mapping functionality of neuralnetworks in visual recognition such as image classification and facerecognition. We present reversible learning for generating and learning latentfeatures using the network itself. By generating latent features correspondingto hard samples and applying the generated features in a training stage,reversible learning can improve a mapping functionality without additional dataaugmentation or handling the bias of dataset. We demonstrate an efficiency ofthe proposed method on the MNIST,Cifar-10/100, and Extremely Biased and poorlycategorized dataset (EBPC dataset). The experimental results show that theproposed method can outperform existing state-of-the-art methods in visualrecognition. Extensive analysis shows that our method can efficiently improvethe mapping capability of a network.",https://arxiv.org/abs/1910.09108
['Title:From Importance Sampling to Doubly Robust Policy Gradient'],Artificial Intelligence ,(Submitted on 20 Oct 2019),"Abstract:  We show that policy gradient (PG) and its variance reduction variants can bederived by taking finite difference of function evaluations supplied byestimators from the importance sampling (IS) family for off-policy evaluation(OPE). Starting from the doubly robust (DR) estimator [Jiang and Li, 2016], weprovide a simple derivation of a very general and flexible form of PG, whichsubsumes the state-of-the-art variance reduction technique [Cheng et al., 2019]as its special case and immediately hints at further variance reductionopportunities overlooked by existing literature.",https://arxiv.org/abs/1910.09066









['Title:Amortized Rejection Sampling in Universal Probabilistic Programming'],Artificial Intelligence ,(Submitted on 20 Oct 2019),Abstract:  Existing approaches to amortized inference in probabilistic programs withunbounded loops can produce estimators with infinite variance. An instance ofthis is importance sampling inference in programs that explicitly includerejection sampling as part of the user-programmed generative procedure. In thispaper we develop a new and efficient amortized importance sampling estimator.We prove finite variance of our estimator and empirically demonstrate ourmethod's correctness and efficiency compared to existing alternatives ongenerative programs containing rejection sampling loops and discuss how toimplement our method in a generic probabilistic programming framework.,https://arxiv.org/abs/1910.09056
['Title:CAI4CAI: The Rise of Contextual Artificial Intelligence in Computer Assisted Interventions'],Artificial Intelligence ,(Submitted on 20 Oct 2019),"Abstract:  Data-driven computational approaches have evolved to enable extraction ofinformation from medical images with a reliability, accuracy and speed which isalready transforming their interpretation and exploitation in clinicalpractice. While similar benefits are longed for in the field of interventionalimaging, this ambition is challenged by a much higher heterogeneity. Clinicalworkflows within interventional suites and operating theatres are extremelycomplex and typically rely on poorly integrated intra-operative devices,sensors, and support infrastructures. Taking stock of some of the most excitingdevelopments in machine learning and artificial intelligence for computerassisted interventions, we highlight the crucial need to take context and humanfactors into account in order to address these challenges. Contextualartificial intelligence for computer assisted intervention, or CAI4CAI, arisesas an emerging opportunity feeding into the broader field of surgical datascience. Central challenges being addressed in CAI4CAI include how to integratethe ensemble of prior knowledge and instantaneous sensory information fromexperts, sensors and actuators; how to create and communicate a faithful andactionable shared representation of the surgery among a mixed human-AI actorteam; how to design interventional systems and associated cognitive sharedcontrol schemes for online uncertainty-aware collaborative decision makingultimately producing more precise and reliable interventions.",https://arxiv.org/abs/1910.09031
"[""Title:Computer-supported Analysis of Positive Properties, Ultrafilters and Modal Collapse in Variants of Gdel's Ontological Argument""]",Artificial Intelligence ,(Submitted on 20 Oct 2019),"Abstract:  Three variants of Kurt Gdel's ontological argument, as proposed byDanaScott, C. Anthony Anderson and Melvin Fitting, are encoded and rigorouslyassessed on the computer. In contrast to Scott's version of Gdel's argument,the two variants contributed by Anderson and Fitting avoid modal collapse.Although they appear quite different on a cursory reading, they are in factclosely related, as our computer-supported formal analysis (conducted in theproof assistant system Isabelle/HOL) reveals. Key to our formal analysis is theutilization of suitably adapted notions of (modal) ultrafilters, and a carefuldistinction between extensions and intensions of positive properties.",https://arxiv.org/abs/1910.08955
['Title:Electric Sheep Team Description Paper Humanoid League Kid-Size 2019'],Artificial Intelligence ,(Submitted on 20 Oct 2019),"Abstract:  In this paper we introduce the newly formed New Zealand based RoboCupHumanoid Kid-Size team, Electric Sheep. We describe our developed humanoidrobot platform, particularly our unique take on the chassis, electronics anduse of several motor types to create a low-cost entry platform. To support thishardware, we discuss our software framework, vision processing, walking andgame-play strategy methodology. Lastly we give an overview of future researchinterests within the team and intentions of future contributions for the leagueand the goal of RoboCup.",https://arxiv.org/abs/1910.08949
['Title:Autonomous Industrial Management via Reinforcement Learning: Self-Learning Agents for Decision-Making -- A Review'],Artificial Intelligence ,(Submitted on 20 Oct 2019),"Abstract:  Industry has always been in the pursuit of becoming more economicallyefficient and the current focus has been to reduce human labour using moderntechnologies. Even with cutting edge technologies, which range from packagingrobots to AI for fault detection, there is still some ambiguity on the aims ofsome new systems, namely, whether they are automated or autonomous. In thispaper we indicate the distinctions between automated and autonomous system aswell as review the current literature and identify the core challenges forcreating learning mechanisms of autonomous agents. We discuss using differenttypes of extended realities, such as digital twins, to train reinforcementlearning agents to learn specific tasks through generalization. Oncegeneralization is achieved, we discuss how these can be used to developself-learning agents. We then introduce self-play scenarios and how they can beused to teach self-learning agents through a supportive environment whichfocuses on how the agents can adapt to different real-world environments.",https://arxiv.org/abs/1910.08942
['Title:Policy Learning for Malaria Control'],Artificial Intelligence ,(Submitted on 20 Oct 2019),"Abstract:  Sequential decision making is a typical problem in reinforcement learningwith plenty of algorithms to solve it. However, only a few of them can workeffectively with a very small number of observations. In this report, weintroduce the progress to learn the policy for Malaria Control as aReinforcement Learning problem in the KDD Cup Challenge 2019 and proposediverse solutions to deal with the limited observations problem. We apply theGenetic Algorithm, Bayesian Optimization, Q-learning with sequence breaking tofind the optimal policy for five years in a row with only 20 episodes/100evaluations. We evaluate those algorithms and compare their performance withRandom Search as a baseline. Among these algorithms, Q-Learning with sequencebreaking has been submitted to the challenge and got ranked 7th in KDD Cup.",https://arxiv.org/abs/1910.08926
['Title:RLScheduler: Learn to Schedule HPC Batch Jobs Using Deep Reinforcement Learning'],Artificial Intelligence ,(Submitted on 20 Oct 2019),"Abstract:  We present RLScheduler, a deep reinforcement learning based job scheduler forscheduling independent batch jobs in high-performance computing (HPC)environment. From knowing nothing about scheduling at beginning, RLScheduler isable to autonomously learn how to effectively schedule HPC batch jobs,targeting a given optimization goal. This is achieved by deep reinforcementlearning with the help of specially designed neural network structures andvarious optimizations to stabilize and accelerate the learning. Our resultsshow that RLScheduler can outperform existing heuristic scheduling algorithms,including a manually fine-tuned machine learning-based scheduler on the sameworkload. More importantly, we show that RLScheduler does not blindly over-fitthe given workload to achieve such optimization, instead, it learns generalrules for scheduling batch jobs which can be further applied to differentworkloads and systems to achieve similarly optimized performance. We alsodemonstrate that RLScheduler is capable of adjusting itself along with changinggoals and workloads, making it an attractive solution for the future autonomousHPC management.",https://arxiv.org/abs/1910.08925
['Title:Enhancing Recurrent Neural Networks with Sememes'],Artificial Intelligence ,(Submitted on 20 Oct 2019),"Abstract:  Sememes, the minimum semantic units of human languages, have beensuccessfully utilized in various natural language processing applications.However, most existing studies exploit sememes in specific tasks and fewefforts are made to utilize sememes more fundamentally. In this paper, wepropose to incorporate sememes into recurrent neural networks (RNNs) to improvetheir sequence modeling ability, which is beneficial to all kinds of downstreamtasks. We design three different sememe incorporation methods and employ themin typical RNNs including LSTM, GRU and their bidirectional variants. Forevaluation, we use several benchmark datasets involving PTB and WikiText-2 forlanguage modeling, SNLI for natural language inference. Experimental resultsshow evident and consistent improvement of our sememe-incorporated modelscompared with vanilla RNNs, which proves the effectiveness of our sememeincorporation methods. Moreover, we find the sememe-incorporated models havegreat robustness and outperform adversarial training in defending adversarialattack. All the code and data of this work will be made available to thepublic.",https://arxiv.org/abs/1910.08910
['Title:Personalizing Graph Neural Networks with Attention Mechanism for Session-based Recommendation'],Artificial Intelligence ,(Submitted on 20 Oct 2019),"Abstract:  The problem of personalized session-based recommendation aims to predictusers' next click based on their sequential behaviors. Existing session-basedrecommendation methods only consider all sessions of user as a single sequence,ignoring the relationship of among sessions. Other than that, most of themneglect complex transitions of items and the collaborative relationship betweenusers and items. To this end, we propose a novel method, named PersonalizingGraph Neural Networks with Attention Mechanism, A-PGNN for brevity. A-PGNNmainly consists of two components: One is Personalizing Graph Neural Network(PGNN), which is used to capture complex transitions in user session sequence.Compared with the traditional Graph Neural Network (GNN) model, it alsoconsiders the role of users in the sequence. The other is Dot-Product Attentionmechanism, which draws on the attention mechanism in machine translation toexplicitly model the effect of historical sessions on the current session.These two parts make it possible to learn the multi-level transitionrelationships between items and sessions in user-specific fashion. Extensiveexperiments conducted on two real-world data sets show that A-PGNNsignificantly outperforms the state-of-the-art personalizing session-basedrecommendation methods consistently.",https://arxiv.org/abs/1910.08887
['Title:Reverse Experience Replay'],Artificial Intelligence ,"(Submitted on 19 Oct 2019 (v1), last revised 22 Oct 2019 (this version, v2))","Abstract:  This paper describes an improvement in Deep Q-learning called ReverseExperience Replay (also RER) that solves the problem of sparse rewards andhelps to deal with reward maximizing tasks by sampling transitions successivelyin reverse order. On tasks with enough experience for training and enoughExperience Replay memory capacity, Deep Q-learning Network with ReverseExperience Replay shows competitive results against both Double DQN, with astandard Experience Replay, and vanilla DQN. Also, RER achieves significantlyincreased results in tasks with a lack of experience and Replay memorycapacity.",https://arxiv.org/abs/1910.08780
['Title:Explainable AI: Deep Reinforcement Learning Agents for Residential Demand Side Cost Savings in Smart Grids'],Artificial Intelligence ,(Submitted on 19 Oct 2019),"Abstract:  Motivated by the recent advancements in deep Reinforcement Learning (RL), wedevelop an RL agent to manage the operation of storage devices in a householddesigned to maximize demand-side cost savings. The proposed technique isdata-driven, and the RL agent learns from scratch on how to efficiently use theenergy storage device under variable tariff-structures Contracting the conceptof the ""black box"" where the techniques learned by the agent are ignored. Weexplain the learning progression of the RL agent, and the strategies it followsbased on the capacity of the storage device.",https://arxiv.org/abs/1910.08719
['Title:Context-Driven Data Mining through Bias Removal and Data Incompleteness Mitigation'],Artificial Intelligence ,(Submitted on 19 Oct 2019),"Abstract:  The results of data mining endeavors are majorly driven by data quality.Throughout these deployments, serious show-stopper problems are stillunresolved, such as: data collection ambiguities, data imbalance, hidden biasesin data, the lack of domain information, and data incompleteness. This paper isbased on the premise that context can aid in mitigating these issues. In atraditional data science lifecycle, context is not considered. Context-drivenData Science Lifecycle (C-DSL); the main contribution of this paper, isdeveloped to address these challenges. Two case studies (using data-sets fromsports events) are developed to test C-DSL. Results from both case studies areevaluated using common data mining metrics such as: coefficient ofdetermination (R2 value) and confusion matrices. The work presented in thispaper aims to re-define the lifecycle and introduce tangible improvements toits outcomes.",https://arxiv.org/abs/1910.08670
['Title:OffWorld Gym: open-access physical robotics environment for real-world reinforcement learning benchmark and research'],Artificial Intelligence ,(Submitted on 18 Oct 2019),"Abstract:  Success stories of applied machine learning can be traced back to thedatasets and environments that were put forward as challenges for thecommunity. The challenge that the community sets as a benchmark is usually thechallenge that the community eventually solves. The ultimate challenge ofreinforcement learning research is to train real agents to operate in the realenvironment, but until now there has not been a common real-world RL benchmark.In this work, we present a prototype real-world environment from OffWorld Gym-- a collection of real-world environments for reinforcement learning inrobotics with free public remote access. Close integration into existingecosystem allows the community to start using OffWorld Gym without any priorexperience in robotics and takes away the burden of managing a physicalrobotics system, abstracting it under a familiar API. We introduce a navigationtask, where a robot has to reach a visual beacon on an uneven terrain usingonly the camera input and provide baseline results in both the real environmentand the simulated replica. To start training, visit this https URL.",https://arxiv.org/abs/1910.08639

# 18

Using Local Knowledge Graph Construction to Scale Seq2Seq Models to Multi-Document Inputs

Query-based open-domain NLP tasks require information synthesis from long and diverse web results. Current approaches extractively select portions of web text as input to Sequence-to-Sequence models using methods such as TF-IDF ranking. We propose constructing a local graph structured knowledge base for each query, which compresses the web search information and reduces redundancy. We show that by linearizing the graph into a structured input sequence, models can encode the graph representations within a standard Sequence-to-Sequence setting. For two generative tasks with very long text input, long-form question answering and multi-document summarization, feeding graph representations as input can achieve better performance than using retrieved text portions.





['Title:Towards Quantifying Intrinsic Generalization of Deep ReLU Networks'],Artificial Intelligence ,(Submitted on 18 Oct 2019),"Abstract:  Understanding the underlying mechanisms that enable the empirical successesof deep neural networks is essential for further improving their performanceand explaining such networks. Towards this goal, a specific question is how to explain the ""surprising"" behavior of the same over-parametrized deep neuralnetworks that can generalize well on real datasets and at the same time""memorize"" training samples when the labels are randomized. In this paper, wedemonstrate that deep ReLU networks generalize from training samples to newpoints via piece-wise linear interpolation. We provide a quantified analysis onthe generalization ability of a deep ReLU network: Given a fixed point$\mathbf{x}$ and a fixed direction in the input space $\mathcal{S}$, there isalways a segment such that any point on the segment will be classified the sameas the fixed point $\mathbf{x}$. We call this segment the $generalization \interval$. We show that the generalization intervals of a ReLU network behavesimilarly along pairwise directions between samples of the same label in bothreal and random cases on the MNIST and CIFAR-10 datasets. This result suggeststhat the same interpolation mechanism is used in both cases. Additionally, fordatasets using real labels, such networks provide a good approximation of theunderlying manifold in the data, where the changes are much smaller alongtangent directions than along normal directions. On the other hand, however,for datasets with random labels, generalization intervals along mid-lines oftriangles with the same label are much smaller than those on the datasets withreal labels, suggesting different behaviors along other directions. Oursystematic experiments demonstrate for the first time that such deep neuralnetworks generalize through the same interpolation and explain the differencesbetween their performance on datasets with real and random labels.",https://arxiv.org/abs/1910.08581

['Title:Towards Learning Cross-Modal Perception-Trace Models'],KG,(Submitted on 18 Oct 2019),"Abstract:  Representation learning is a key element of state-of-the-art deep learning approaches. It enables to transform raw data into structured vector space embeddings. Such embeddings are able to capture the distributional semantics of their context, e.g. by word windows on natural language sentences, graph walks on knowledge graphs or convolutions on images. So far, this context is manually defined, resulting in heuristics which are solely optimized for computational performance on certain tasks like link-prediction. However, such heuristic models of context are fundamentally different to how humans capture information. For instance, when reading a multi-modal webpage (i) humans do not perceive all parts of a document equally: Some words and parts of images are skipped, others are revisited several times which makes the perception trace highly non-sequential; (ii) humans construct meaning from a document's content by shifting their attention between text and image, among other things, guided by layout and design elements. In this paper we empirically investigate the difference between human perception and context heuristics of basic embedding models. We conduct eye tracking experiments to capture the underlying characteristics of human perception of media documents containing a mixture of text and images. Based on that, we devise a prototypical computational perception-trace model, called CMPM. We evaluate empirically how CMPM can improve a basic skip-gram embedding approach. Our results suggest, that even with a basic human-inspired computational perception model, there is a huge potential for improving embeddings since such a model does inherently capture multiple modalities, as well as layout and design elements.",https://arxiv.org/abs/1910.08549







['Title:A flexible integer linear programming formulation for scheduling clinician on-call service in hospitals'],Artificial Intelligence ,(Submitted on 18 Oct 2019),"Abstract:  Scheduling of personnel in a hospital environment is vital to improving theservice provided to patients and balancing the workload assigned to clinicians.Many approaches have been tried and successfully applied to generate efficientschedules in such settings. However, due to the computational complexity of thescheduling problem in general, most approaches resort to heuristics to find anon-optimal solution in a reasonable amount of time. We designed an integerlinear programming formulation to find an optimal schedule in a clinicaldivision of a hospital. Our formulation mitigates issues related tocomputational complexity by minimizing the set of constraints, yet retainssufficient flexibility so that it can be adapted to a variety of clinicaldivisions.We then conducted a case study for our approach using data from theInfectious Diseases division at St. Michael's Hospital in Toronto, Canada. Weanalyzed and compared the results of our approach to manually-created schedulesat the hospital, and found improved adherence to departmental constraints andclinician preferences. We used simulated data to examine the sensitivity of theruntime of our linear program for various parameters and observed reassuringresults, signifying the practicality and generalizability of our approach indifferent real-world scenarios.",https://arxiv.org/abs/1910.08526
['Title:Reflecting After Learning for Understanding'],Artificial Intelligence ,(Submitted on 18 Oct 2019),"Abstract:  Today, image classification is a common way for systems to process visualcontent. Although neural network approaches to classification have seen greatprogress in reducing error rates, it is not clear what this means for acognitive system that needs to make sense of the multiple and competingpredictions from its own classifiers. As a step to address this, we present anovel framework that uses meta-reasoning and meta-operations to unifypredictions into abstractions, properties, or relationships. Using theframework on images from ImageNet, we demonstrate systems that unify 41% to 46%of predictions in general and unify 67% to 75% of predictions when the systemscan explain their conceptual differences. We also demonstrate a system in ""thewild"" by feeding live video images through it and show it unifying 51% ofpredictions in general and 69% of predictions when their differences can beexplained conceptually by the system. In a survey given to 24 participants, wefound that 87% of the unified predictions describe their corresponding images.",https://arxiv.org/abs/1910.08243
['Title:Planning for Goal-Oriented Dialogue Systems'],Artificial Intelligence ,(Submitted on 17 Oct 2019),"Abstract:  Generating complex multi-turn goal-oriented dialogue agents is a difficultproblem that has seen a considerable focus from many leaders in the techindustry, including IBM, Google, Amazon, and Microsoft. This is in large partdue to the rapidly growing market demand for dialogue agents capable ofgoal-oriented behaviour. Due to the business process nature of theseconversations, end-to-end machine learning systems are generally not a viableoption, as the generated dialogue agents must be deployable and verifiable onbehalf of the businesses authoring them.In this work, we propose a paradigm shift in the creation of goal-orientedcomplex dialogue systems that dramatically eliminates the need for a designerto manually specify a dialogue tree, which nearly all current systems have toresort to when the interaction pattern falls outside standard patterns such asslot filling. We propose a declarative representation of the dialogue agent tobe processed by state-of-the-art planning technology. Our proposed approachcovers all aspects of the process; from model solicitation to the execution ofthe generated plans/dialogue agents. Along the way, we introduce novel planningencodings for declarative dialogue synthesis, a variety of interfaces forworking with the specification as a dialogue architect, and a robust executorfor generalized contingent plans. We have created prototype implementations ofall components, and in this paper, we further demonstrate the resulting systemempirically.",https://arxiv.org/abs/1910.08137
['Title:MultiVerse: Causal Reasoning using Importance Sampling in Probabilistic Programming'],Artificial Intelligence ,(Submitted on 17 Oct 2019),"Abstract:  We elaborate on using importance sampling for causal reasoning, in particularfor counterfactual inference. We show how this can be implemented natively inprobabilistic programming. By considering the structure of the counterfactualquery, one can significantly optimise the inference process. We also considerdesign choices to enable further optimisations. We introduce MultiVerse, aprobabilistic programming prototype engine for approximate causal reasoning. Weprovide experimental results and compare with Pyro, an existing probabilisticprogramming framework with some of causal reasoning tools.",https://arxiv.org/abs/1910.08091
['Title:Towards Computing Inferences from English News Headlines'],Artificial Intelligence ,(Submitted on 18 Oct 2019),"Abstract:  Newspapers are a popular form of written discourse, read by many people,thanks to the novelty of the information provided by the news content in it. Aheadline is the most widely read part of any newspaper due to its appearance ina bigger font and sometimes in colour print. In this paper, we suggest andimplement a method for computing inferences from English news headlines,excluding the information from the context in which the headlines appear. Thismethod attempts to generate the possible assumptions a reader formulates inmind upon reading a fresh headline. The generated inferences could be usefulfor assessing the impact of the news headline on readers including children.The understandability of the current state of social affairs depends greatly onthe assimilation of the headlines. As the inferences that are independent ofthe context depend mainly on the syntax of the headline, dependency trees ofheadlines are used in this approach, to find the syntactical structure of theheadlines and to compute inferences out of them.",https://arxiv.org/abs/1910.08294
['Title:Follow Alice into the Rabbit Hole: Giving Dialogue Agents Understanding of Human Level Attributes'],Artificial Intelligence ,(Submitted on 18 Oct 2019),"Abstract:  For conversational AI and virtual assistants to communicate with humans in arealistic way, they must exhibit human characteristics such as expression ofemotion and personality. Current attempts toward constructing human-likedialogue agents have presented significant difficulties. We propose Human LevelAttributes (HLAs) based on tropes as the basis of a method for learningdialogue agents that can imitate the personalities of fictional characters.Tropes are characteristics of fictional personalities that are observedrecurrently and determined by viewers' impressions. By combining detailed HLAdata with dialogue data for specific characters, we present a dataset thatmodels character profiles and gives dialogue agents the ability to learncharacters' language styles through their HLAs. We then introduce athree-component system, ALOHA (which stands for Artificial Learning On HumanAttributes), that combines character space mapping, character communitydetection, and language style retrieval to build a character (or personality)specific language model. Our preliminary experiments demonstrate that ALOHA,combined with our proposed dataset, can outperform baseline models atidentifying correct dialogue responses of any chosen target character, and isstable regardless of the character's identity, genre of the show, and contextof the dialogue.",https://arxiv.org/abs/1910.08293
['Title:Unsupervised Context Rewriting for Open Domain Conversation'],Artificial Intelligence ,(Submitted on 18 Oct 2019),"Abstract:  Context modeling has a pivotal role in open domain conversation. Existingworks either use heuristic methods or jointly learn context modeling andresponse generation with an encoder-decoder framework. This paper proposes anexplicit context rewriting method, which rewrites the last utterance byconsidering context history. We leverage pseudo-parallel data and elaborate acontext rewriting network, which is built upon the CopyNet with thereinforcement learning method. The rewritten utterance is beneficial tocandidate retrieval, explainable context modeling, as well as enabling toemploy a single-turn framework to the multi-turn scenario. The empiricalresults show that our model outperforms baselines in terms of the rewritingquality, the multi-turn response generation, and the end-to-end retrieval-basedchatbots.",https://arxiv.org/abs/1910.08282
['Title:RTFM: Generalising to Novel Environment Dynamics via Reading'],Artificial Intelligence ,(Submitted on 18 Oct 2019),"Abstract:  Obtaining policies that can generalise to new environments in reinforcementlearning is challenging. In this work, we demonstrate that languageunderstanding via a reading policy learner is a promising vehicle forgeneralisation to new environments. We propose a grounded policy learningproblem, Read to Fight Monsters (RTFM), in which the agent must jointly reasonover a language goal, relevant dynamics described in a document, andenvironment observations. We procedurally generate environment dynamics andcorresponding language descriptions of the dynamics, such that agents must readto understand new environment dynamics instead of memorising any particularinformation. In addition, we propose txt2$\pi$, a model that captures three-wayinteractions between the goal, document, and observations. On RTFM, txt2$\pi$generalises to new environments with dynamics not seen during training viareading. Furthermore, our model outperforms baselines such as FiLM andlanguage-conditioned CNNs on RTFM. Through curriculum learning, txt2$\pi$produces policies that excel on complex RTFM tasks requiring several reasoningand coreference steps.",https://arxiv.org/abs/1910.08210



 KG







